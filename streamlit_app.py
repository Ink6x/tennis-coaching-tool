import streamlit as st
import json
import numpy as np
import faiss
from pathlib import Path
import os
from openai import OpenAI
import pickle
import hashlib
import time

# ==========================================
# è¨­å®šï¼ˆStreamlit Cloudç”¨ï¼‰
# ==========================================

# OpenAI APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secretsï¼‰
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or st.secrets.get('OPENAI_API_KEY')

# APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.warning("""
    **Streamlit Community Cloud ã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. ã‚¢ãƒ—ãƒªã® Settings â†’ Secrets ã‚’é–‹ã
    2. ä»¥ä¸‹ã‚’è¿½åŠ :
    ```
    OPENAI_API_KEY = "sk-proj-your-api-key-here"
    ```
    3. Save ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. ã‚¢ãƒ—ãƒªã‚’ Reboot
    
    **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    2. ä»¥ä¸‹ã‚’è¨˜å…¥:
    ```
    OPENAI_API_KEY=sk-proj-your-api-key-here
    ```
    """)
    st.stop()

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secrets or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
APP_PASSWORD = os.getenv('APP_PASSWORD') or st.secrets.get('APP_PASSWORD', 'coaching2025')

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º
def find_data_file():
    """students.json ã®å ´æ‰€ã‚’è‡ªå‹•æ¤œå‡º"""
    possible_paths = [
        'students.json',
        'data/students.json',
        Path(__file__).parent / 'students.json',
        Path(__file__).parent / 'data' / 'students.json'
    ]
    
    for path in possible_paths:
        p = Path(path)
        if p.exists():
            return str(p)
    
    return None

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
DATA_FILE = find_data_file()

if not DATA_FILE:
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (students.json) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.warning("""
    **è§£æ±ºæ–¹æ³•:**
    
    1. **GitHubãƒªãƒã‚¸ãƒˆãƒªã« students.json ã‚’è¿½åŠ **:
    ```bash
    git add students.json
    git commit -m "Add students data file"
    git push
    ```
    
    2. **ã¾ãŸã¯ data/ ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®**:
    ```
    coaching-tool/
    â”œâ”€â”€ streamlit_app.py
    â””â”€â”€ data/
        â””â”€â”€ students.json  â† ã“ã“ã«é…ç½®
    ```
    
    3. **Streamlit Cloudã§ã‚¢ãƒ—ãƒªã‚’ Reboot**
    """)
    st.stop()

# ==========================================
# RAGã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹
# ==========================================

class CoachingAssistant:
    def __init__(self, data_file=None):
        """
        ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
        
        Args:
            data_file (str, optional): ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.data_file = data_file or DATA_FILE
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.index = None
        self.chunks = []
        self.chunk_metadata = []
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜å…ˆ
        self.index_dir = Path("data")
        self.index_dir.mkdir(exist_ok=True)
        self.index_path = self.index_dir / "faiss_index.bin"
        self.chunks_path = self.index_dir / "chunks.pkl"
        
    def load_data(self):
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_file}")
            st.stop()
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
            st.stop()
    
    def get_data_hash(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œçŸ¥ç”¨ï¼‰"""
        with open(self.data_file, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def chunk_data(self, data):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆé…åˆ—å½¢å¼ã¨è¾æ›¸å½¢å¼ã®ä¸¡æ–¹ã«å¯¾å¿œï¼‰"""
        chunks = []
        metadata = []
        
        # dataãŒé…åˆ—ã®å ´åˆã¨è¾æ›¸ã®å ´åˆã®ä¸¡æ–¹ã«å¯¾å¿œ
        if isinstance(data, list):
            # é…åˆ—å½¢å¼ã®å ´åˆ
            for student in data:
                student_id = student.get('id', student.get('student_id', 'unknown'))
                self._process_student(student_id, student, chunks, metadata)
        else:
            # è¾æ›¸å½¢å¼ã®å ´åˆ
            for student_id, student in data.items():
                self._process_student(student_id, student, chunks, metadata)
        
        return chunks, metadata
    
    def _process_student(self, student_id, student, chunks, metadata):
        """ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ"""
        # åŸºæœ¬æƒ…å ±ãƒãƒ£ãƒ³ã‚¯
        basic_info = f"""
ç”Ÿå¾’ID: {student_id}
åå‰: {student.get('name', 'ä¸æ˜')}
å¹´é½¢: {student.get('age', 'ä¸æ˜')}æ­³
å­¦å¹´: {student.get('grade', 'ä¸æ˜')}
ç«¶æŠ€: {student.get('sport', 'ä¸æ˜')}
"""
        chunks.append(basic_info.strip())
        metadata.append({
            'student_id': student_id,
            'type': 'basic_info',
            'name': student.get('name', 'ä¸æ˜')
        })
        
        # ç›®æ¨™è¨­å®šã®è¨˜éŒ²
        if 'records' in student:
            for idx, record in enumerate(student['records'], 1):
                record_text = f"""
ã€ç”Ÿå¾’: {student.get('name', 'ä¸æ˜')} ({student_id})ã€‘
ã‚»ãƒƒã‚·ãƒ§ãƒ³æ—¥: {record.get('date', 'ä¸æ˜')}
ç¾åœ¨ã®çŠ¶æ³: {record.get('current_situation', 'è¨˜éŒ²ãªã—')}
ç›®æ¨™: {record.get('goal', 'è¨˜éŒ²ãªã—')}
å–ã‚Šçµ„ã¿å†…å®¹: {record.get('approach', 'è¨˜éŒ²ãªã—')}
æŒ¯ã‚Šè¿”ã‚Š: {record.get('reflection', 'è¨˜éŒ²ãªã—')}
ã‚³ãƒ¼ãƒã®ãƒ¡ãƒ¢: {record.get('coach_notes', 'è¨˜éŒ²ãªã—')}
"""
                chunks.append(record_text.strip())
                metadata.append({
                    'student_id': student_id,
                    'type': 'record',
                    'record_index': idx,
                    'date': record.get('date', 'ä¸æ˜'),
                    'name': student.get('name', 'ä¸æ˜')
                })
    
    def get_embedding(self, text, model="text-embedding-3-small"):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—"""
        try:
            text = text.replace("\n", " ")
            response = self.client.embeddings.create(input=[text], model=model)
            return response.data[0].embedding
        except Exception as e:
            st.error(f"âŒ Embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_embeddings_batch(self, texts, model="text-embedding-3-small", batch_size=1):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ï¼ˆè¶…ä¿å®ˆçš„ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œï¼‰"""
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch = [text.replace("\n", " ") for text in batch]
            
            try:
                response = self.client.embeddings.create(input=batch, model=model)
                embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(embeddings)
                
                # é€²æ—è¡¨ç¤º
                progress = min(i + len(batch), len(texts))
                st.info(f"å‡¦ç†ä¸­: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯ï¼ˆç´„{int(progress/len(texts)*100)}%ï¼‰")
                
            except Exception as e:
                error_msg = str(e)
                st.error(f"âŒ Batch embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼ãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€ã‚ˆã‚Šé•·ãå¾…ã¤
                if "rate" in error_msg.lower() or "429" in error_msg:
                    st.warning("â±ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’æ¤œå‡ºã€‚60ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™...")
                    time.sleep(60)
                    # å†è©¦è¡Œ
                    try:
                        response = self.client.embeddings.create(input=batch, model=model)
                        embeddings = [item.embedding for item in response.data]
                        all_embeddings.extend(embeddings)
                        progress = min(i + len(batch), len(texts))
                        st.success(f"âœ… å†è©¦è¡ŒæˆåŠŸ: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯")
                    except Exception as e2:
                        st.error(f"âŒ å†è©¦è¡Œã‚‚å¤±æ•—: {e2}")
                        st.warning("""
                        **è§£æ±ºæ–¹æ³•:**
                        1. æ–°ã—ã„APIã‚­ãƒ¼ã‚’ä½œæˆ
                        2. Organization/Projectã®è¨­å®šã‚’ç¢ºèª
                        3. Tierï¼ˆåˆ©ç”¨ãƒ—ãƒ©ãƒ³ï¼‰ã‚’ç¢ºèª
                        """)
                        return None
                else:
                    st.warning("""
                    **ã“ã®ã‚¨ãƒ©ãƒ¼ã®åŸå› :**
                    - APIã‚­ãƒ¼ã®å•é¡Œ
                    - Project/Organizationã®åˆ¶é™
                    
                    **è§£æ±ºæ–¹æ³•:**
                    1. æ–°ã—ã„APIã‚­ãƒ¼ã‚’ä½œæˆ
                    2. Limitsãƒšãƒ¼ã‚¸ã§åˆ¶é™ã‚’ç¢ºèª
                    """)
                    return None
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆéå¸¸ã«ä¿å®ˆçš„ï¼‰
            if i + batch_size < len(texts):
                time.sleep(5.0)  # 2ç§’ â†’ 5ç§’ã«å¤‰æ›´
        
        return all_embeddings
    
    def build_index(self):
        """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        data = self.load_data()
        
        # ãƒãƒ£ãƒ³ã‚¯åŒ–
        self.chunks, self.chunk_metadata = self.chunk_data(data)
        
        st.info(f"ğŸ“Š {len(self.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ä¸­...")
        
        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å–å¾—
        embeddings = self.get_embeddings_batch(self.chunks)
        
        if not embeddings:
            st.error("âŒ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # NumPyé…åˆ—ã«å¤‰æ›
        embeddings_np = np.array(embeddings, dtype=np.float32)
        
        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        dimension = embeddings_np.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings_np)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        faiss.write_index(self.index, str(self.index_path))
        
        # ãƒãƒ£ãƒ³ã‚¯ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        with open(self.chunks_path, 'wb') as f:
            pickle.dump({
                'chunks': self.chunks,
                'metadata': self.chunk_metadata,
                'data_hash': self.get_data_hash()
            }, f)
        
        st.success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†: {len(self.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
        return True
    
    def load_index(self):
        """ä¿å­˜æ¸ˆã¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if not self.index_path.exists() or not self.chunks_path.exists():
                return False
            
            # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿ãŒæ›´æ–°ã•ã‚Œã¦ã„ãªã„ã‹ï¼‰
            with open(self.chunks_path, 'rb') as f:
                saved_data = pickle.load(f)
            
            # saved_dataãŒè¾æ›¸ã§ãªã„å ´åˆã¯å¤ã„å½¢å¼ãªã®ã§å‰Šé™¤
            if not isinstance(saved_data, dict):
                st.warning("âš ï¸ å¤ã„å½¢å¼ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¤œå‡ºã€‚å‰Šé™¤ã—ã¦å†æ§‹ç¯‰ã—ã¾ã™ã€‚")
                self.index_path.unlink(missing_ok=True)
                self.chunks_path.unlink(missing_ok=True)
                return False
            
            current_hash = self.get_data_hash()
            if saved_data.get('data_hash') != current_hash:
                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã™ã€‚")
                return False
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿
            self.index = faiss.read_index(str(self.index_path))
            self.chunks = saved_data['chunks']
            self.chunk_metadata = saved_data['metadata']
            
            return True
        except Exception as e:
            st.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            try:
                self.index_path.unlink(missing_ok=True)
                self.chunks_path.unlink(missing_ok=True)
            except:
                pass
            return False
    
    def search(self, query, k=5):
        """ã‚¯ã‚¨ãƒªã«é¡ä¼¼ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
        if self.index is None:
            st.error("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—
        query_embedding = self.get_embedding(query)
        
        if query_embedding is None:
            return []
        
        query_vector = np.array([query_embedding], dtype=np.float32)
        
        # æ¤œç´¢å®Ÿè¡Œ
        distances, indices = self.index.search(query_vector, k)
        
        # çµæœã‚’æ•´å½¢
        results = []
        for idx, distance in zip(indices[0], distances[0]):
            if idx < len(self.chunks):
                results.append({
                    'chunk': self.chunks[idx],
                    'metadata': self.chunk_metadata[idx],
                    'distance': float(distance)
                })
        
        return results
    
    def get_answer(self, query, model="gpt-4o-mini"):
        """RAGã‚’ä½¿ã£ã¦è³ªå•ã«å›ç­”"""
        # é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢
        search_results = self.search(query, k=5)
        
        if not search_results:
            return "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", []
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = "\n\n---\n\n".join([r['chunk'] for r in search_results])
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = f"""ã‚ãªãŸã¯å­ä¾›å‘ã‘(10-18æ­³)ã®1on1ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚’è¡Œã†ã‚³ãƒ¼ãƒã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç”Ÿå¾’ã¸ã®ç›®æ¨™è¨­å®šã‚„æŒ‡å°ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€å‚è€ƒã¨ãªã‚‹éå»ã®ãƒ‡ãƒ¼ã‚¿ã€‘
{context}

ã€è³ªå•ã€‘
{query}

ã€å›ç­”ã®æŒ‡é‡ã€‘
- éå»ã®æˆåŠŸäº‹ä¾‹ã‚„åŠ¹æœçš„ã ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ç”Ÿå¾’ã®å¹´é½¢ã‚„çŠ¶æ³ã«å¿œã˜ãŸå…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„
- ã‚³ãƒ¼ãƒãƒ³ã‚°çš„ãªè¦–ç‚¹ï¼ˆå‚¾è´ã€è³ªå•ã€ç›®æ¨™è¨­å®šï¼‰ã‚’é‡è¦–ã—ã¦ãã ã•ã„
- å®Ÿè·µçš„ã§è¡Œå‹•ã«ã¤ãªãŒã‚‹ææ¡ˆã‚’å¿ƒãŒã‘ã¦ãã ã•ã„

å›ç­”:"""
        
        try:
            # OpenAI APIã§å›ç­”ç”Ÿæˆ
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            return answer, search_results
        
        except Exception as e:
            st.error(f"âŒ å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", search_results

# ==========================================
# Streamlitã‚¢ãƒ—ãƒª
# ==========================================

def main():
    st.set_page_config(
        page_title="ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸ¾",
        layout="wide"
    )
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
        st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
        
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password == APP_PASSWORD:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error("âŒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        return
    
    # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
    st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
    st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
    st.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {DATA_FILE}")
    
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
    if 'assistant' not in st.session_state:
        with st.spinner("ğŸ“‚ ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            assistant = CoachingAssistant()
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãªã‘ã‚Œã°æ§‹ç¯‰ï¼‰
            if assistant.load_index():
                st.success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(assistant.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            else:
                st.warning("âš ï¸ ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°è¦æ§‹ç¯‰ã—ã¾ã™...")
                if assistant.build_index():
                    st.balloons()
                else:
                    st.error("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return
            
            st.session_state.assistant = assistant
    
    assistant = st.session_state.assistant
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_name = st.selectbox(
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
            ["gpt-5.1", "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
            index=0
        )
        
        st.markdown("---")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰", type="secondary"):
            with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­..."):
                if assistant.build_index():
                    st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    st.rerun()
        
        # çµ±è¨ˆæƒ…å ±
        st.markdown("---")
        st.markdown("### ğŸ“Š çµ±è¨ˆæƒ…å ±")
        st.metric("ãƒãƒ£ãƒ³ã‚¯æ•°", len(assistant.chunks))
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        data = assistant.load_data()
        if isinstance(data, list):
            st.metric("ç”Ÿå¾’æ•°", len(data))
            total_records = sum(len(s.get('records', [])) for s in data)
        else:
            st.metric("ç”Ÿå¾’æ•°", len(data))
            total_records = sum(len(s.get('records', [])) for s in data.values())
        st.metric("è¨˜éŒ²æ•°", total_records)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    st.markdown("---")
    
    # æ¤œç´¢å…¥åŠ›
    st.subheader("ğŸ” è³ªå•ã‚’å…¥åŠ›")
    query = st.text_area(
        "ä¾‹: ãƒ†ãƒ‹ã‚¹ã§è©¦åˆã«å‹ã¦ãªã„ä¸­å­¦ç”Ÿã«ã©ã®ã‚ˆã†ãªç›®æ¨™è¨­å®šã‚’ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ",
        height=100,
        placeholder="éå»ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‚è€ƒã«ãªã‚‹æƒ…å ±ã‚’æ¤œç´¢ã—ã¾ã™..."
    )
    
    # æ¤œç´¢å®Ÿè¡Œ
    col1, col2 = st.columns([1, 5])
    with col1:
        search_button = st.button("ğŸ” æ¤œç´¢", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            st.rerun()
    
    if search_button and query:
        with st.spinner("ğŸ¤– AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            answer, search_results = assistant.get_answer(query, model=model_name)
        
        # å›ç­”è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ’¬ AI ã®å›ç­”")
        st.markdown(answer)
        
        # å‚è€ƒãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“š å‚è€ƒã«ã—ãŸéå»ã®ãƒ‡ãƒ¼ã‚¿")
        
        for i, result in enumerate(search_results, 1):
            with st.expander(f"ğŸ“„ å‚è€ƒãƒ‡ãƒ¼ã‚¿ {i} - {result['metadata'].get('name', 'ä¸æ˜')} ({result['metadata'].get('type', 'unknown')})"):
                st.text(result['chunk'])
                st.caption(f"é–¢é€£åº¦ã‚¹ã‚³ã‚¢: {result['distance']:.4f}")

if __name__ == "__main__":
    main()
