import streamlit as st
import json
import numpy as np
import faiss
from pathlib import Path
import os
from openai import OpenAI
import pickle
import hashlib
import time

# ==========================================
# è¨­å®šï¼ˆStreamlit Cloudç”¨ï¼‰
# ==========================================

# OpenAI APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secretsï¼‰
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or st.secrets.get('OPENAI_API_KEY')

# APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.warning("""
    **Streamlit Community Cloud ã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. ã‚¢ãƒ—ãƒªã® Settings â†’ Secrets ã‚’é–‹ã
    2. ä»¥ä¸‹ã‚’è¿½åŠ :
    ```
    OPENAI_API_KEY = "sk-proj-your-api-key-here"
    ```
    3. Save ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. ã‚¢ãƒ—ãƒªã‚’ Reboot
    
    **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    2. ä»¥ä¸‹ã‚’è¨˜å…¥:
    ```
    OPENAI_API_KEY=sk-proj-your-api-key-here
    ```
    """)
    st.stop()

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secrets or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
APP_PASSWORD = os.getenv('APP_PASSWORD') or st.secrets.get('APP_PASSWORD', 'coaching2025')

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º
def find_data_file():
    """students.json ã®å ´æ‰€ã‚’è‡ªå‹•æ¤œå‡º"""
    possible_paths = [
        'students.json',
        'data/students.json',
        Path(__file__).parent / 'students.json',
        Path(__file__).parent / 'data' / 'students.json'
    ]
    
    for path in possible_paths:
        p = Path(path)
        if p.exists():
            return str(p)
    
    return None

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
DATA_FILE = find_data_file()

if not DATA_FILE:
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (students.json) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.warning("""
    **è§£æ±ºæ–¹æ³•:**
    
    1. **GitHubãƒªãƒã‚¸ãƒˆãƒªã« students.json ã‚’è¿½åŠ **:
    ```bash
    git add students.json
    git commit -m "Add students data file"
    git push
    ```
    
    2. **ã¾ãŸã¯ data/ ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®**:
    ```
    coaching-tool/
    â”œâ”€â”€ streamlit_app.py
    â””â”€â”€ data/
        â””â”€â”€ students.json  â† ã“ã“ã«é…ç½®
    ```
    
    3. **Streamlit Cloudã§ã‚¢ãƒ—ãƒªã‚’ Reboot**
    """)
    st.stop()

# ==========================================
# RAGã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹
# ==========================================

class CoachingAssistant:
    def __init__(self, data_file=None):
        """
        ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
        
        Args:
            data_file (str, optional): ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.data_file = data_file or DATA_FILE
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.index = None
        self.chunks = []
        self.chunk_metadata = []
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜å…ˆ
        self.index_dir = Path("data")
        self.index_dir.mkdir(exist_ok=True)
        self.index_path = self.index_dir / "faiss_index.bin"
        self.chunks_path = self.index_dir / "chunks.pkl"
        
    def load_data(self):
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_file}")
            st.stop()
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
            st.stop()
    
    def get_data_hash(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œçŸ¥ç”¨ï¼‰"""
        with open(self.data_file, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def chunk_data(self, data):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿå¾’ã”ã¨ã«ã¾ã¨ã‚ãŸå¤§ããªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
        chunks = []
        metadata = []
        
        # å„ç”Ÿå¾’ã®ãƒ‡ãƒ¼ã‚¿ã‚’1-2å€‹ã®å¤§ããªãƒãƒ£ãƒ³ã‚¯ã«ã¾ã¨ã‚ã‚‹
        for student in data:
            student_name = student.get('name', 'ä¸æ˜')
            
            # === ãƒãƒ£ãƒ³ã‚¯1: Vision + Plan ã®çµ±åˆãƒãƒ£ãƒ³ã‚¯ ===
            vision_plan_content = f"ã€ç”Ÿå¾’å: {student_name}ã€‘\n\n"
            
            # Visionæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿½åŠ 
            if 'vision' in student and student['vision']:
                vision_plan_content += "â–  Visionï¼ˆç›®æ¨™è¨­å®šï¼‰\n"
                for idx, vision in enumerate(student['vision'], 1):
                    if vision.get('goal'):
                        vision_plan_content += f"  ç›®æ¨™{idx}: {vision['goal']}\n"
                    
                    if 'reasons' in vision:
                        reasons = vision['reasons']
                        if any([reasons.get('visible_self'), reasons.get('invisible_self'), 
                               reasons.get('visible_others'), reasons.get('invisible_others')]):
                            vision_plan_content += "  é”æˆã—ãŸã„ç†ç”±:\n"
                            if reasons.get('visible_self'):
                                vision_plan_content += f"    è¦‹ãˆã‚‹ãƒ»è‡ªåˆ†: {'; '.join(reasons['visible_self'])}\n"
                            if reasons.get('invisible_self'):
                                vision_plan_content += f"    è¦‹ãˆãªã„ãƒ»è‡ªåˆ†: {'; '.join(reasons['invisible_self'])}\n"
                            if reasons.get('visible_others'):
                                vision_plan_content += f"    è¦‹ãˆã‚‹ãƒ»ä»–äºº: {'; '.join(reasons['visible_others'])}\n"
                            if reasons.get('invisible_others'):
                                vision_plan_content += f"    è¦‹ãˆãªã„ãƒ»ä»–äºº: {'; '.join(reasons['invisible_others'])}\n"
                    
                    if vision.get('routine'):
                        vision_plan_content += f"  ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³: {'; '.join(vision['routine'])}\n"
                    vision_plan_content += "\n"
            
            # Planæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿½åŠ 
            if 'plan' in student and student['plan']:
                vision_plan_content += "â–  Planï¼ˆè¨ˆç”»ï¼‰\n"
                for idx, plan in enumerate(student['plan'], 1):
                    if plan.get('goal'):
                        vision_plan_content += f"  è¨ˆç”»ç›®æ¨™{idx}: {plan['goal']}\n"
                    if plan.get('strengths'):
                        vision_plan_content += f"  æ­¦å™¨: {plan['strengths']}\n"
                    if plan.get('challenges'):
                        vision_plan_content += f"  èª²é¡Œ: {plan['challenges']}\n"
                    
                    if 'steps' in plan and plan['steps']:
                        vision_plan_content += "  ã‚¹ãƒ†ãƒƒãƒ—:\n"
                        for step in plan['steps']:
                            vision_plan_content += f"    - {step.get('date', 'ä¸æ˜')}: {step.get('goal', '')} "
                            if step.get('details'):
                                vision_plan_content += f"({step['details']})"
                            vision_plan_content += "\n"
                    vision_plan_content += "\n"
            
            # Vision + Planã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ ï¼ˆå†…å®¹ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if len(vision_plan_content.strip()) > 50:
                chunks.append(vision_plan_content.strip())
                metadata.append({
                    'student_name': student_name,
                    'type': 'vision_plan',
                    'content_type': 'Vision+Plançµ±åˆ'
                })
            
            # === ãƒãƒ£ãƒ³ã‚¯2: Review + Meeting Memos ã®çµ±åˆãƒãƒ£ãƒ³ã‚¯ ===
            review_memo_content = f"ã€ç”Ÿå¾’å: {student_name}ã€‘\n\n"
            
            # Reviewæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿½åŠ 
            if 'review' in student and student['review']:
                review_memo_content += "â–  Reviewï¼ˆæŒ¯ã‚Šè¿”ã‚Šï¼‰\n"
                for idx, review in enumerate(student['review'], 1):
                    review_memo_content += f"  æŒ¯ã‚Šè¿”ã‚Š{idx}:\n"
                    
                    if review.get('achievement_score'):
                        review_memo_content += f"    é”æˆåº¦è©•ä¾¡: {review['achievement_score']}\n"
                    if review.get('quantitative'):
                        review_memo_content += f"    å®šé‡è©•ä¾¡: {review['quantitative']}\n"
                    if review.get('qualitative'):
                        review_memo_content += f"    å®šæ€§è©•ä¾¡: {review['qualitative']}\n"
                    
                    if 'reasons' in review and review['reasons']:
                        review_memo_content += "    ç†ç”±:\n"
                        for reason in review['reasons'][:3]:  # æœ€åˆã®3ã¤ã¾ã§
                            review_memo_content += f"      - {reason}\n"
                        if len(review['reasons']) > 3:
                            review_memo_content += f"      ï¼ˆä»–{len(review['reasons'])-3}ä»¶ï¼‰\n"
                    
                    if 'learnings' in review and review['learnings']:
                        review_memo_content += "    å­¦ã³:\n"
                        for learning in review['learnings'][:3]:  # æœ€åˆã®3ã¤ã¾ã§
                            review_memo_content += f"      - {learning}\n"
                        if len(review['learnings']) > 3:
                            review_memo_content += f"      ï¼ˆä»–{len(review['learnings'])-3}ä»¶ï¼‰\n"
                    
                    if review.get('next_goal'):
                        review_memo_content += f"    æ¬¡ã®ç›®æ¨™: {review['next_goal']}\n"
                    review_memo_content += "\n"
            
            # Meeting Memosæƒ…å ±ã‚’ã¾ã¨ã‚ã¦è¿½åŠ ï¼ˆè¦ç´„ç‰ˆï¼‰
            if 'meeting_memos' in student and student['meeting_memos']:
                review_memo_content += "â–  Meeting Memosï¼ˆãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¨˜éŒ²ï¼‰\n"
                for idx, memo in enumerate(student['meeting_memos'][:5], 1):  # æœ€æ–°5ä»¶ã¾ã§
                    content = memo.get('content', '')
                    if content:
                        # å†…å®¹ã‚’è¦ç´„ï¼ˆæœ€åˆã®500æ–‡å­—ã¾ã§ï¼‰
                        summary = content[:500]
                        if len(content) > 500:
                            summary += "..."
                        review_memo_content += f"  MTG{idx} ({memo.get('filename', 'ä¸æ˜')}):\n"
                        review_memo_content += f"    {summary}\n\n"
                
                if len(student['meeting_memos']) > 5:
                    review_memo_content += f"  ï¼ˆä»–{len(student['meeting_memos'])-5}ä»¶ã®ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¨˜éŒ²ï¼‰\n"
            
            # Review + Meeting Memosã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ ï¼ˆå†…å®¹ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if len(review_memo_content.strip()) > 50:
                chunks.append(review_memo_content.strip())
                metadata.append({
                    'student_name': student_name,
                    'type': 'review_memo',
                    'content_type': 'Review+MeetingMemoçµ±åˆ'
                })
        
        return chunks, metadata
    
    def get_embedding(self, text, model="text-embedding-3-small"):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—"""
        try:
            text = text.replace("\n", " ")
            # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯åˆ‡ã‚Šè©°ã‚ï¼ˆ8191ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
            if len(text) > 8000:
                text = text[:8000]
            response = self.client.embeddings.create(input=[text], model=model)
            return response.data[0].embedding
        except Exception as e:
            st.error(f"âŒ Embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_embeddings_batch(self, texts, model="text-embedding-3-small", batch_size=5):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ã‚’åŠ¹ç‡çš„ã«å–å¾—"""
        all_embeddings = []
        progress_placeholder = st.empty()
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            # å„ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚’åˆ¶é™
            batch = [text.replace("\n", " ")[:8000] for text in batch]
            
            try:
                response = self.client.embeddings.create(input=batch, model=model)
                embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(embeddings)
                
                # é€²æ—è¡¨ç¤º
                progress = min(i + len(batch), len(texts))
                progress_placeholder.info(
                    f"å‡¦ç†ä¸­: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯"
                )
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã®ãŸã‚å°‘ã—å¾…ã¤ï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ãŒå°‘ãªã„ã®ã§çŸ­ã‚ã§è‰¯ã„ï¼‰
                if i + batch_size < len(texts):
                    time.sleep(0.2)
                
            except Exception as e:
                error_msg = str(e)
                st.error(f"âŒ Batch embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼ãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€å¾…æ©Ÿã—ã¦å†è©¦è¡Œ
                if "rate" in error_msg.lower() or "429" in error_msg:
                    st.warning("â±ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’æ¤œå‡ºã€‚30ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™...")
                    time.sleep(30)
                    try:
                        response = self.client.embeddings.create(input=batch, model=model)
                        embeddings = [item.embedding for item in response.data]
                        all_embeddings.extend(embeddings)
                        progress = min(i + len(batch), len(texts))
                        st.success(f"âœ… å†è©¦è¡ŒæˆåŠŸ: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯")
                    except Exception as e2:
                        st.error(f"âŒ å†è©¦è¡Œã‚‚å¤±æ•—: {e2}")
                        progress_placeholder.empty()
                        return None
                else:
                    progress_placeholder.empty()
                    return None
        
        progress_placeholder.empty()
        return np.array(all_embeddings)
    
    def build_index(self):
        """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        with st.spinner("ğŸ”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            data = self.load_data()
            
            # ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
            self.chunks, self.chunk_metadata = self.chunk_data(data)
            
            if not self.chunks:
                st.error("âŒ ãƒãƒ£ãƒ³ã‚¯ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            st.info(f"ğŸ“„ {len(self.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ")
            
            # Embeddingså–å¾—ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããï¼‰
            embeddings = self.get_embeddings_batch(self.chunks, batch_size=5)
            
            if embeddings is None:
                st.error("âŒ Embeddingã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            dimension = embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dimension)
            self.index.add(embeddings)
            
            # ä¿å­˜
            try:
                faiss.write_index(self.index, str(self.index_path))
                with open(self.chunks_path, 'wb') as f:
                    pickle.dump({
                        'chunks': self.chunks,
                        'metadata': self.chunk_metadata,
                        'hash': self.get_data_hash()
                    }, f)
                st.success("ğŸ’¾ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as e:
                st.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜ã«å¤±æ•—: {e}")
            
            return True
    
    def load_index(self):
        """ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            if not self.index_path.exists() or not self.chunks_path.exists():
                return False
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            with open(self.chunks_path, 'rb') as f:
                saved_data = pickle.load(f)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            current_hash = self.get_data_hash()
            if saved_data.get('hash') != current_hash:
                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã™...")
                return False
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
            self.index = faiss.read_index(str(self.index_path))
            self.chunks = saved_data['chunks']
            self.chunk_metadata = saved_data['metadata']
            
            return True
        except Exception as e:
            st.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def search(self, query, k=5):
        """ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
        if self.index is None:
            return []
        
        # ã‚¯ã‚¨ãƒªã®Embeddingå–å¾—
        query_embedding = self.get_embedding(query)
        if query_embedding is None:
            return []
        
        query_vec = np.array([query_embedding])
        
        # æ¤œç´¢å®Ÿè¡Œ
        distances, indices = self.index.search(query_vec, min(k, len(self.chunks)))
        
        results = []
        for idx, distance in zip(indices[0], distances[0]):
            if idx < len(self.chunks):
                results.append({
                    'chunk': self.chunks[idx],
                    'metadata': self.chunk_metadata[idx],
                    'distance': float(distance),
                    'similarity': 1 / (1 + float(distance))
                })
        
        return results
    
    def get_answer(self, query, model="gpt-4o-mini"):
        """RAGã‚’ä½¿ã£ã¦è³ªå•ã«å›ç­”"""
        # é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢ï¼ˆãƒãƒ£ãƒ³ã‚¯æ•°ãŒå°‘ãªã„ã®ã§ä¸Šä½5å€‹ã§ååˆ†ï¼‰
        search_results = self.search(query, k=5)
        
        if not search_results:
            return "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", []
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = "ã€éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£ã™ã‚‹æƒ…å ±ã€‘\n\n"
        for i, result in enumerate(search_results, 1):
            context += f"--- é–¢é€£æƒ…å ± {i} (é–¢é€£åº¦: {result['similarity']:.2f}) ---\n"
            context += f"{result['chunk']}\n\n"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = """ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒã§ã™ã€‚
éå»ã®ç”Ÿå¾’ã®è©³ç´°ãªã‚³ãƒ¼ãƒãƒ³ã‚°è¨˜éŒ²ï¼ˆç›®æ¨™è¨­å®šã€è¨ˆç”»ã€æŒ¯ã‚Šè¿”ã‚Šã€ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¨˜éŒ²ï¼‰ã‚’å‚ç…§ã§ãã¾ã™ã€‚

ã€å›ç­”ã®åŸå‰‡ã€‘
1. å…·ä½“çš„ãªç”Ÿå¾’åã¨äº‹ä¾‹ã‚’å¼•ç”¨ã™ã‚‹ã“ã¨
2. ç‰¹å®šã®ç«¶æŠ€ã‚„å­¦å¹´ã€å¹´é½¢ã€æˆç¸¾ãªã©ï¼‰ãŒä¸€è‡´ã™ã‚‹å ´åˆã¯ã€ãã‚Œã‚‰ã®æƒ…å ±ã‚’æ˜ç¤ºã™ã‚‹ã“ã¨
3. æˆåŠŸä¾‹ã ã‘ã§ãªãã€èª²é¡Œã‚„æ”¹å–„ç‚¹ã‚‚å«ã‚ã‚‹ã“ã¨
4. å®Ÿåœ¨ã®éå»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã™ã‚‹ã“ã¨
5. æ¨æ¸¬ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸäº‹å®Ÿã‚’è¿°ã¹ã‚‹ã“ã¨

ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
## çµè«–
[è³ªå•ã¸ã®ç›´æ¥çš„ãªå›ç­”ã‚’2-3è¡Œã§]

## å…·ä½“çš„ãªå‚è€ƒäº‹ä¾‹
[éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£ã™ã‚‹äº‹ä¾‹ã‚’2-3ã¤ç´¹ä»‹]

## æ¨å¥¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
[ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ãˆã‚‹åŠ¹æœçš„ãªæ–¹æ³•ã‚’ç®‡æ¡æ›¸ãã§3-5å€‹]

## æ³¨æ„ç‚¹
[é¿ã‘ã‚‹ã¹ãã“ã¨ã‚„æ°—ã‚’ã¤ã‘ã‚‹ç‚¹ã‚’2-3å€‹]"""
        
        prompt = f"{context}\n\nè³ªå•: {query}"
        
        try:
            # OpenAI APIã§å›ç­”ç”Ÿæˆ
            if model.lower().startswith("gpt-5") or model.lower().startswith("o1"):
                # o1/gpt-5ã‚·ãƒªãƒ¼ã‚ºç”¨ã®è¨­å®š
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "user", "content": f"{system_prompt}\n\n{prompt}"}
                    ],
                    max_completion_tokens=8000
                )
            else:
                # é€šå¸¸ã®GPTãƒ¢ãƒ‡ãƒ«ç”¨
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.7
                )
            
            answer = response.choices[0].message.content
            
            if not answer or answer.strip() == "":
                answer = "å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            return answer, search_results
        
        except Exception as e:
            st.error(f"âŒ å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", search_results

# ==========================================
# Streamlitã‚¢ãƒ—ãƒª
# ==========================================

def main():
    st.set_page_config(
        page_title="ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸ¾",
        layout="wide"
    )
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
        st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
        
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password == APP_PASSWORD:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error("âŒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        
        st.info("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: coaching2025")
        return
    
    # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
    st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
    st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
    
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
    if 'assistant' not in st.session_state:
        with st.spinner("ğŸ“‚ åˆæœŸåŒ–ä¸­..."):
            assistant = CoachingAssistant()
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãªã‘ã‚Œã°æ§‹ç¯‰ï¼‰
            if assistant.load_index():
                st.success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(assistant.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            else:
                st.info("âš ï¸ åˆå›èµ·å‹•ã®ãŸã‚ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™...")
                if assistant.build_index():
                    st.balloons()
                else:
                    st.error("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return
            
            st.session_state.assistant = assistant
    
    assistant = st.session_state.assistant
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_name = st.selectbox(
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
            ["gpt-5.1", "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
            index=0
        )
        
        st.markdown("---")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰", type="secondary"):
            with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­..."):
                if assistant.build_index():
                    st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    st.rerun()
        
        # çµ±è¨ˆæƒ…å ±
        st.markdown("---")
        st.markdown("### ğŸ“Š çµ±è¨ˆæƒ…å ±")
        st.metric("ãƒãƒ£ãƒ³ã‚¯æ•°", len(assistant.chunks))
        st.metric("ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šã®å¹³å‡æ–‡å­—æ•°", 
                  int(sum(len(c) for c in assistant.chunks) / len(assistant.chunks)) if assistant.chunks else 0)
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        data = assistant.load_data()
        st.metric("ç”Ÿå¾’æ•°", len(data))
        
        # ç”Ÿå¾’ä¸€è¦§ï¼ˆä¸Šä½5åã®ã¿è¡¨ç¤ºï¼‰
        st.subheader("ç”Ÿå¾’ä¸€è¦§ï¼ˆä¸Šä½5åï¼‰")
        for student in data[:5]:
            st.write(f"â€¢ {student.get('name', 'ä¸æ˜')}")
        if len(data) > 5:
            st.write(f"  ä»–{len(data)-5}å")
    
    # ã‚µãƒ³ãƒ—ãƒ«è³ªå•ãƒœã‚¿ãƒ³
    st.header("ğŸ” è³ªå•ã‚’å…¥åŠ›")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ“Œ 16æ­³ä»¥ä¸‹ã§4Cå¤§ä¼šãƒ™ã‚¹ãƒˆ4ã‚’ç›®æŒ‡ã™ã«ã¯?"):
            st.session_state.query = "16æ­³ä»¥ä¸‹ã®4Cå¤§ä¼šã§ãƒ™ã‚¹ãƒˆ4ã«å…¥ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªç·´ç¿’æ–¹æ³•ã¨ç›®æ¨™è¨­å®šã‚’æ•™ãˆã¦ãã ã•ã„"
    with col2:
        if st.button("ğŸ“Œ è©¦åˆã®å…¥ã‚Šã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã¯?"):
            st.session_state.query = "è©¦åˆã®åºç›¤ã§ãƒŸã‚¹ãŒå¤šã„ç”Ÿå¾’ã¸ã®æŒ‡å°æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
    with col3:
        if st.button("ğŸ“Œ ãƒ¡ãƒ³ã‚¿ãƒ«å¼·åŒ–ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯?"):
            st.session_state.query = "ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã«å¼±ã„ç”Ÿå¾’ã®ãƒ¡ãƒ³ã‚¿ãƒ«å¼·åŒ–æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
    
    # æ¤œç´¢å…¥åŠ›
    query = st.text_area(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        value=st.session_state.get('query', ''),
        height=100,
        placeholder="ä¾‹: ãƒ†ãƒ‹ã‚¹ã§è©¦åˆã«å‹ã¦ãªã„ä¸­å­¦ç”Ÿã«ã©ã®ã‚ˆã†ãªç›®æ¨™è¨­å®šã‚’ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ"
    )
    
    # æ¤œç´¢å®Ÿè¡Œ
    col1, col2 = st.columns([1, 5])
    with col1:
        search_button = st.button("ğŸ” æ¤œç´¢", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            if 'query' in st.session_state:
                del st.session_state.query
            st.rerun()
    
    if search_button and query:
        with st.spinner("ğŸ¤– AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            answer, search_results = assistant.get_answer(query, model=model_name)
        
        # å›ç­”è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ’¬ AI ã®å›ç­”")
        st.markdown(answer)
        
        # å‚è€ƒãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        if search_results:
            st.markdown("---")
            st.subheader("ğŸ“š å‚è€ƒã«ã—ãŸéå»ã®ãƒ‡ãƒ¼ã‚¿")
            
            for i, result in enumerate(search_results, 1):
                student_name = result['metadata'].get('student_name', 'ä¸æ˜')
                content_type = result['metadata'].get('content_type', '')
                similarity = result['similarity']
                
                with st.expander(
                    f"{i}. {student_name} - {content_type} (é–¢é€£åº¦: {similarity:.1%})"
                ):
                    # ãƒãƒ£ãƒ³ã‚¯å†…å®¹ã‚’æ•´å½¢ã—ã¦è¡¨ç¤º
                    content_lines = result['chunk'].split('\n')
                    for line in content_lines[:30]:  # æœ€åˆã®30è¡Œã¾ã§è¡¨ç¤º
                        if line.strip():
                            st.text(line)
                    if len(content_lines) > 30:
                        st.text("...")
                        st.caption(f"ï¼ˆå…¨{len(content_lines)}è¡Œï¼‰")
    
    # ä»˜å¸¯æƒ…å ±
    st.markdown("---")
    st.caption(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {DATA_FILE} | ğŸ’¾ ãƒãƒ£ãƒ³ã‚¯æ•°: {len(assistant.chunks)}")

if __name__ == "__main__":
    main()
