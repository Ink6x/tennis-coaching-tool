import streamlit as st
import json
import numpy as np
import faiss
from pathlib import Path
import os
from openai import OpenAI
import pickle
import hashlib
import time

# ==========================================
# è¨­å®šï¼ˆStreamlit Cloudç”¨ï¼‰
# ==========================================

# OpenAI APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secretsï¼‰
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') or st.secrets.get('OPENAI_API_KEY')

# APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.warning("""
    **Streamlit Community Cloud ã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. ã‚¢ãƒ—ãƒªã® Settings â†’ Secrets ã‚’é–‹ã
    2. ä»¥ä¸‹ã‚’è¿½åŠ :
    ```
    OPENAI_API_KEY = "sk-proj-your-api-key-here"
    ```
    3. Save ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. ã‚¢ãƒ—ãƒªã‚’ Reboot
    
    **ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®è§£æ±ºæ–¹æ³•:**
    
    1. `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    2. ä»¥ä¸‹ã‚’è¨˜å…¥:
    ```
    OPENAI_API_KEY=sk-proj-your-api-key-here
    ```
    """)
    st.stop()

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•° or Streamlit Secrets or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
APP_PASSWORD = os.getenv('APP_PASSWORD') or st.secrets.get('APP_PASSWORD', 'coaching2025')

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è‡ªå‹•æ¤œå‡º
def find_data_file():
    """students.json ã®å ´æ‰€ã‚’è‡ªå‹•æ¤œå‡º"""
    possible_paths = [
        'students.json',
        'data/students.json',
        Path(__file__).parent / 'students.json',
        Path(__file__).parent / 'data' / 'students.json'
    ]
    
    for path in possible_paths:
        p = Path(path)
        if p.exists():
            return str(p)
    
    return None

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
DATA_FILE = find_data_file()

if not DATA_FILE:
    st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (students.json) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.warning("""
    **è§£æ±ºæ–¹æ³•:**
    
    1. **GitHubãƒªãƒã‚¸ãƒˆãƒªã« students.json ã‚’è¿½åŠ **:
    ```bash
    git add students.json
    git commit -m "Add students data file"
    git push
    ```
    
    2. **ã¾ãŸã¯ data/ ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®**:
    ```
    coaching-tool/
    â”œâ”€â”€ streamlit_app.py
    â””â”€â”€ data/
        â””â”€â”€ students.json  â† ã“ã“ã«é…ç½®
    ```
    
    3. **Streamlit Cloudã§ã‚¢ãƒ—ãƒªã‚’ Reboot**
    """)
    st.stop()

# ==========================================
# RAGã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹
# ==========================================

class CoachingAssistant:
    def __init__(self, data_file=None):
        """
        ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
        
        Args:
            data_file (str, optional): ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.data_file = data_file or DATA_FILE
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.index = None
        self.chunks = []
        self.chunk_metadata = []
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜å…ˆ
        self.index_dir = Path("data")
        self.index_dir.mkdir(exist_ok=True)
        self.index_path = self.index_dir / "faiss_index.bin"
        self.chunks_path = self.index_dir / "chunks.pkl"
        
    def load_data(self):
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.data_file}")
            st.stop()
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: {e}")
            st.stop()
    
    def get_data_hash(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆå¤‰æ›´æ¤œçŸ¥ç”¨ï¼‰"""
        with open(self.data_file, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def chunk_data(self, data):
        """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«åˆã‚ã›ãŸå®Ÿè£…ï¼‰"""
        chunks = []
        metadata = []
        
        # ãƒ‡ãƒ¼ã‚¿ã¯é…åˆ—å½¢å¼ã§ç”Ÿå¾’æƒ…å ±ã‚’å«ã‚€
        for student in data:
            student_name = student.get('name', 'ä¸æ˜')
            
            # åŸºæœ¬æƒ…å ±ãƒãƒ£ãƒ³ã‚¯
            basic_info = f"""
ç”Ÿå¾’å: {student_name}
"""
            # Visionãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
            if 'vision' in student:
                for vision in student['vision']:
                    if vision.get('goal'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Visionï¼ˆç›®æ¨™è¨­å®šï¼‰
ç›®æ¨™: {vision['goal']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'vision',
                            'subtype': 'ç›®æ¨™'
                        })
                    
                    # é”æˆç†ç”±ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
                    if 'reasons' in vision:
                        reasons_text = []
                        reasons = vision['reasons']
                        if reasons.get('visible_self'):
                            reasons_text.append("ã€è¦‹ãˆã‚‹ãƒ»è‡ªåˆ†ã€‘" + '; '.join(reasons['visible_self']))
                        if reasons.get('invisible_self'):
                            reasons_text.append("ã€è¦‹ãˆãªã„ãƒ»è‡ªåˆ†ã€‘" + '; '.join(reasons['invisible_self']))
                        if reasons.get('visible_others'):
                            reasons_text.append("ã€è¦‹ãˆã‚‹ãƒ»ä»–äººã€‘" + '; '.join(reasons['visible_others']))
                        if reasons.get('invisible_others'):
                            reasons_text.append("ã€è¦‹ãˆãªã„ãƒ»ä»–äººã€‘" + '; '.join(reasons['invisible_others']))
                        
                        if reasons_text:
                            chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Visionï¼ˆé”æˆç†ç”±ï¼‰
é”æˆã—ãŸã„ç†ç”±: {' '.join(reasons_text)}
"""
                            chunks.append(chunk_text.strip())
                            metadata.append({
                                'student_name': student_name,
                                'type': 'vision',
                                'subtype': 'é”æˆç†ç”±'
                            })
                    
                    # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
                    if vision.get('routine'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Visionï¼ˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ï¼‰
ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³: {'; '.join(vision['routine'])}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'vision',
                            'subtype': 'ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³'
                        })
            
            # Planãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
            if 'plan' in student:
                for plan in student['plan']:
                    if plan.get('goal'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Planï¼ˆè¨ˆç”»ï¼‰
è¨ˆç”»ç›®æ¨™: {plan['goal']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'plan',
                            'subtype': 'è¨ˆç”»ç›®æ¨™'
                        })
                    
                    if plan.get('strengths'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Planï¼ˆæ­¦å™¨ï¼‰
æ­¦å™¨: {plan['strengths']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'plan',
                            'subtype': 'æ­¦å™¨'
                        })
                    
                    if plan.get('challenges'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Planï¼ˆèª²é¡Œï¼‰
èª²é¡Œ: {plan['challenges']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'plan',
                            'subtype': 'èª²é¡Œ'
                        })
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
                    if 'steps' in plan:
                        for step in plan['steps']:
                            chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Planï¼ˆã‚¹ãƒ†ãƒƒãƒ—ï¼‰
æ—¥ä»˜: {step.get('date', 'ä¸æ˜')}
ç›®æ¨™: {step.get('goal', '')}
è©³ç´°: {step.get('details', '')}
"""
                            chunks.append(chunk_text.strip())
                            metadata.append({
                                'student_name': student_name,
                                'type': 'plan',
                                'subtype': 'ã‚¹ãƒ†ãƒƒãƒ—',
                                'date': step.get('date', 'ä¸æ˜')
                            })
            
            # Reviewãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
            if 'review' in student:
                for review in student['review']:
                    if review.get('achievement_score'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆæŒ¯ã‚Šè¿”ã‚Šï¼‰
é”æˆåº¦è©•ä¾¡: {review['achievement_score']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'review',
                            'subtype': 'é”æˆåº¦'
                        })
                    
                    if review.get('quantitative'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆå®šé‡è©•ä¾¡ï¼‰
å®šé‡è©•ä¾¡: {review['quantitative']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'review',
                            'subtype': 'å®šé‡è©•ä¾¡'
                        })
                    
                    if review.get('qualitative'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆå®šæ€§è©•ä¾¡ï¼‰
å®šæ€§è©•ä¾¡: {review['qualitative']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'review',
                            'subtype': 'å®šæ€§è©•ä¾¡'
                        })
                    
                    # ç†ç”±ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
                    if 'reasons' in review:
                        for reason in review['reasons']:
                            chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆé”æˆ/æœªé”æˆã®ç†ç”±ï¼‰
ç†ç”±: {reason}
"""
                            chunks.append(chunk_text.strip())
                            metadata.append({
                                'student_name': student_name,
                                'type': 'review',
                                'subtype': 'ç†ç”±'
                            })
                    
                    # å­¦ã³ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
                    if 'learnings' in review:
                        for learning in review['learnings']:
                            chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆå­¦ã³ï¼‰
å­¦ã‚“ã ã“ã¨: {learning}
"""
                            chunks.append(chunk_text.strip())
                            metadata.append({
                                'student_name': student_name,
                                'type': 'review',
                                'subtype': 'å­¦ã³'
                            })
                    
                    if review.get('next_goal'):
                        chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Reviewï¼ˆæ¬¡ã®ç›®æ¨™ï¼‰
æ¬¡ã®ç›®æ¨™: {review['next_goal']}
"""
                        chunks.append(chunk_text.strip())
                        metadata.append({
                            'student_name': student_name,
                            'type': 'review',
                            'subtype': 'æ¬¡ã®ç›®æ¨™'
                        })
            
            # Meeting Memosã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–
            if 'meeting_memos' in student:
                for memo in student['meeting_memos']:
                    content = memo.get('content', '')
                    if content:
                        # é•·ã„ãƒ¡ãƒ¢ã¯åˆ†å‰²
                        chunk_size = 500
                        for i in range(0, len(content), chunk_size):
                            chunk_content = content[i:i+chunk_size]
                            if len(chunk_content.strip()) > 50:  # çŸ­ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã¯ç„¡è¦–
                                chunk_text = f"""
ã€ç”Ÿå¾’: {student_name}ã€‘
ã‚¿ã‚¤ãƒ—: Meeting Memo
å†…å®¹: {chunk_content}
"""
                                chunks.append(chunk_text.strip())
                                metadata.append({
                                    'student_name': student_name,
                                    'type': 'meeting_memo',
                                    'filename': memo.get('filename', 'ä¸æ˜')
                                })
        
        return chunks, metadata
    
    def get_embedding(self, text, model="text-embedding-3-small"):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—"""
        try:
            text = text.replace("\n", " ")
            response = self.client.embeddings.create(input=[text], model=model)
            return response.data[0].embedding
        except Exception as e:
            st.error(f"âŒ Embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_embeddings_batch(self, texts, model="text-embedding-3-small", batch_size=1):
        """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ã‚’åŠ¹ç‡çš„ã«å–å¾—ï¼ˆè¶…ä¿å®ˆçš„ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œï¼‰"""
        all_embeddings = []
        progress_placeholder = st.empty()
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch = [text.replace("\n", " ") for text in batch]
            
            try:
                response = self.client.embeddings.create(input=batch, model=model)
                embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(embeddings)
                
                # é€²æ—è¡¨ç¤º
                progress = min(i + len(batch), len(texts))
                progress_placeholder.info(
                    f"å‡¦ç†ä¸­: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯ï¼ˆç´„{int(progress/len(texts)*100)}%ï¼‰"
                )
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã®ãŸã‚å°‘ã—å¾…ã¤
                if i + batch_size < len(texts):
                    time.sleep(0.5)
                
            except Exception as e:
                error_msg = str(e)
                st.error(f"âŒ Batch embeddingå–å¾—ã‚¨ãƒ©ãƒ¼: {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼ãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å ´åˆã€ã‚ˆã‚Šé•·ãå¾…ã¤
                if "rate" in error_msg.lower() or "429" in error_msg:
                    st.warning("â±ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’æ¤œå‡ºã€‚60ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™...")
                    time.sleep(60)
                    # å†è©¦è¡Œ
                    try:
                        response = self.client.embeddings.create(input=batch, model=model)
                        embeddings = [item.embedding for item in response.data]
                        all_embeddings.extend(embeddings)
                        progress = min(i + len(batch), len(texts))
                        st.success(f"âœ… å†è©¦è¡ŒæˆåŠŸ: {progress}/{len(texts)} ãƒãƒ£ãƒ³ã‚¯")
                    except Exception as e2:
                        st.error(f"âŒ å†è©¦è¡Œã‚‚å¤±æ•—: {e2}")
                        progress_placeholder.empty()
                        return None
                else:
                    progress_placeholder.empty()
                    return None
        
        progress_placeholder.empty()
        return np.array(all_embeddings)
    
    def build_index(self):
        """FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        with st.spinner("ğŸ”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            data = self.load_data()
            
            # ãƒãƒ£ãƒ³ã‚¯ä½œæˆ
            self.chunks, self.chunk_metadata = self.chunk_data(data)
            
            if not self.chunks:
                st.error("âŒ ãƒãƒ£ãƒ³ã‚¯ãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            st.info(f"ğŸ“„ {len(self.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ")
            
            # Embeddingså–å¾—ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼šãƒãƒƒãƒã‚µã‚¤ã‚º1ï¼‰
            embeddings = self.get_embeddings_batch(self.chunks, batch_size=1)
            
            if embeddings is None:
                st.error("âŒ Embeddingã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            dimension = embeddings.shape[1]
            self.index = faiss.IndexFlatL2(dimension)
            self.index.add(embeddings)
            
            # ä¿å­˜
            try:
                faiss.write_index(self.index, str(self.index_path))
                with open(self.chunks_path, 'wb') as f:
                    pickle.dump({
                        'chunks': self.chunks,
                        'metadata': self.chunk_metadata,
                        'hash': self.get_data_hash()
                    }, f)
                st.success("ğŸ’¾ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            except Exception as e:
                st.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¿å­˜ã«å¤±æ•—: {e}")
            
            return True
    
    def load_index(self):
        """ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            if not self.index_path.exists() or not self.chunks_path.exists():
                return False
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            with open(self.chunks_path, 'rb') as f:
                saved_data = pickle.load(f)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            current_hash = self.get_data_hash()
            if saved_data.get('hash') != current_hash:
                st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ã—ã¾ã™...")
                return False
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
            self.index = faiss.read_index(str(self.index_path))
            self.chunks = saved_data['chunks']
            self.chunk_metadata = saved_data['metadata']
            
            return True
        except Exception as e:
            st.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def search(self, query, k=10):
        """ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢"""
        if self.index is None:
            return []
        
        # ã‚¯ã‚¨ãƒªã®Embeddingå–å¾—
        query_embedding = self.get_embedding(query)
        if query_embedding is None:
            return []
        
        query_vec = np.array([query_embedding])
        
        # æ¤œç´¢å®Ÿè¡Œ
        distances, indices = self.index.search(query_vec, min(k, len(self.chunks)))
        
        results = []
        for idx, distance in zip(indices[0], distances[0]):
            if idx < len(self.chunks):
                results.append({
                    'chunk': self.chunks[idx],
                    'metadata': self.chunk_metadata[idx],
                    'distance': float(distance),
                    'similarity': 1 / (1 + float(distance))
                })
        
        return results
    
    def get_answer(self, query, model="gpt-4o-mini"):
        """RAGã‚’ä½¿ã£ã¦è³ªå•ã«å›ç­”"""
        # é–¢é€£ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢
        search_results = self.search(query, k=15)
        
        if not search_results:
            return "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", []
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        context = "ã€éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£ã™ã‚‹æƒ…å ±ã€‘\n\n"
        for i, result in enumerate(search_results, 1):
            context += f"--- é–¢é€£æƒ…å ± {i} (é–¢é€£åº¦: {result['similarity']:.2f}) ---\n"
            context += f"{result['chunk']}\n\n"
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = """ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒã§ã™ã€‚
éå»ã®ç”Ÿå¾’ã®è©³ç´°ãªã‚³ãƒ¼ãƒãƒ³ã‚°è¨˜éŒ²ï¼ˆç›®æ¨™è¨­å®šã€è¨ˆç”»ã€æŒ¯ã‚Šè¿”ã‚Šã€ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¨˜éŒ²ï¼‰ã‚’å‚ç…§ã§ãã¾ã™ã€‚

ã€å›ç­”ã®åŸå‰‡ã€‘
1. å¿…ãšå…·ä½“çš„ãªç”Ÿå¾’åã¨äº‹ä¾‹ã‚’å¼•ç”¨ã™ã‚‹ã“ã¨
2. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼ˆæœŸé–“ã€é”æˆåº¦ã€é »åº¦ãªã©ï¼‰ã‚’æ˜ç¤ºã™ã‚‹ã“ã¨
3. æˆåŠŸä¾‹ã ã‘ã§ãªãã€å¤±æ•—ä¾‹ã‚„å›°é›£ã ã£ãŸç‚¹ã‚‚å«ã‚ã‚‹ã“ã¨
4. è¤‡æ•°ã®ç”Ÿå¾’ã®äº‹ä¾‹ã‚’æ¯”è¼ƒãƒ»çµ±åˆã—ã¦å›ç­”ã™ã‚‹ã“ã¨
5. æ¨æ¸¬ã§ã¯ãªãã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸäº‹å®Ÿã®ã¿ã‚’è¿°ã¹ã‚‹ã“ã¨

ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
## çµè«–ï¼ˆç«¯çš„ã«ï¼‰
[è³ªå•ã¸ã®ç›´æ¥çš„ãªå›ç­”ã‚’1-2è¡Œã§]

## å…·ä½“çš„äº‹ä¾‹
**[ç”Ÿå¾’å]ã®äº‹ä¾‹:**
- ç›®æ¨™: [å…·ä½“çš„ãªç›®æ¨™]
- æœŸé–“: [Xé€±é–“/Xãƒ¶æœˆ]
- ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: [å…·ä½“çš„ãªæ–¹æ³•]
- çµæœ: [é”æˆåº¦ãƒ»å­¦ã³]
- é‡è¦ãƒã‚¤ãƒ³ãƒˆ: [æˆåŠŸ/å¤±æ•—ã®è¦å› ]

ï¼ˆ2-3åã®äº‹ä¾‹ã‚’è¨˜è¼‰ï¼‰

## ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ãˆã‚‹å‚¾å‘
- [è¤‡æ•°äº‹ä¾‹ã‹ã‚‰è¦‹ãˆã‚‹å…±é€šç‚¹]
- [åŠ¹æœçš„ã ã£ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ]
- [é¿ã‘ã‚‹ã¹ãè½ã¨ã—ç©´]

## æ¨å¥¨äº‹é …
1. [å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³1]ï¼ˆæ ¹æ‹ : [ç”Ÿå¾’å]ã®äº‹ä¾‹ï¼‰
2. [å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³2]ï¼ˆæ ¹æ‹ : [ç”Ÿå¾’å]ã®äº‹ä¾‹ï¼‰
3. [å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³3]ï¼ˆæ ¹æ‹ : [ç”Ÿå¾’å]ã®äº‹ä¾‹ï¼‰"""
        
        prompt = f"{context}\n\nè³ªå•: {query}"
        
        try:
            # OpenAI APIã§å›ç­”ç”Ÿæˆ
            if model.lower().startswith("gpt-5") or model.lower().startswith("o1"):
                # o1/gpt-5ã‚·ãƒªãƒ¼ã‚ºç”¨ã®è¨­å®š
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "user", "content": f"{system_prompt}\n\n{prompt}"}
                    ],
                    max_completion_tokens=8000
                )
            else:
                # é€šå¸¸ã®GPTãƒ¢ãƒ‡ãƒ«ç”¨
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.7
                )
            
            answer = response.choices[0].message.content
            
            if not answer or answer.strip() == "":
                answer = "å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            return answer, search_results
        
        except Exception as e:
            st.error(f"âŒ å›ç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", search_results

# ==========================================
# Streamlitã‚¢ãƒ—ãƒª
# ==========================================

def main():
    st.set_page_config(
        page_title="ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸ¾",
        layout="wide"
    )
    
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
        st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
        
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password == APP_PASSWORD:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error("âŒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
        
        st.info("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: coaching2025")
        return
    
    # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
    st.title("ğŸ¾ ãƒ†ãƒ‹ã‚¹ã‚³ãƒ¼ãƒãƒ³ã‚°åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«")
    st.write("éå»ã®ç”Ÿå¾’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ–°ã—ã„ç›®æ¨™è¨­å®šã®å‚è€ƒæƒ…å ±ã‚’AIæ¤œç´¢ã§ãã¾ã™")
    
    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®åˆæœŸåŒ–
    if 'assistant' not in st.session_state:
        with st.spinner("ğŸ“‚ ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            assistant = CoachingAssistant()
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãªã‘ã‚Œã°æ§‹ç¯‰ï¼‰
            if assistant.load_index():
                st.success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(assistant.chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
            else:
                st.warning("âš ï¸ ä¿å­˜æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°è¦æ§‹ç¯‰ã—ã¾ã™...")
                if assistant.build_index():
                    st.balloons()
                else:
                    st.error("âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return
            
            st.session_state.assistant = assistant
    
    assistant = st.session_state.assistant
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_name = st.selectbox(
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
            ["gpt-5.1", "gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
            index=0
        )
        
        st.markdown("---")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰", type="secondary"):
            with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­..."):
                if assistant.build_index():
                    st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    st.rerun()
        
        # çµ±è¨ˆæƒ…å ±
        st.markdown("---")
        st.markdown("### ğŸ“Š çµ±è¨ˆæƒ…å ±")
        st.metric("ãƒãƒ£ãƒ³ã‚¯æ•°", len(assistant.chunks))
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
        data = assistant.load_data()
        st.metric("ç”Ÿå¾’æ•°", len(data))
        
        # ç”Ÿå¾’ä¸€è¦§ï¼ˆä¸Šä½10åï¼‰
        st.subheader("ç”Ÿå¾’ä¸€è¦§")
        for student in data[:10]:
            with st.expander(student.get('name', 'ä¸æ˜')):
                st.write(f"Vision: {len(student.get('vision', []))}ä»¶")
                st.write(f"Plan: {len(student.get('plan', []))}ä»¶")
                st.write(f"Review: {len(student.get('review', []))}ä»¶")
                st.write(f"MTGãƒ¡ãƒ¢: {len(student.get('meeting_memos', []))}ä»¶")
    
    # ã‚µãƒ³ãƒ—ãƒ«è³ªå•ãƒœã‚¿ãƒ³
    st.header("ğŸ” è³ªå•ã‚’å…¥åŠ›")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ“Œ 3ãƒ¶æœˆã§é–¢æ±å¤§ä¼šã«å‡ºå ´ã™ã‚‹ã«ã¯?"):
            st.session_state.query = "3ãƒ¶æœˆã§é–¢æ±å¤§ä¼šã«å‡ºå ´ã™ã‚‹ãŸã‚ã«ã¯ï¼Ÿ"
    with col2:
        if st.button("ğŸ“Œ ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰å¼·åŒ–ã®æˆåŠŸä¾‹ã¯?"):
            st.session_state.query = "12æ­³ã§ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ã‚’å¼·åŒ–ã—ãŸã„ç”Ÿå¾’ã®æˆåŠŸä¾‹ã‚’æ•™ãˆã¦"
    with col3:
        if st.button("ğŸ“Œ è‡ªä¿¡ã‚’ã¤ã‘ã‚‹æ–¹æ³•ã¯?"):
            st.session_state.query = "è‡ªä¿¡ã‚’ã¤ã‘ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ•™ãˆã¦"
    
    # æ¤œç´¢å…¥åŠ›
    query = st.text_area(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        value=st.session_state.get('query', ''),
        height=120,
        placeholder="ä¾‹: ãƒ†ãƒ‹ã‚¹ã§è©¦åˆã«å‹ã¦ãªã„ä¸­å­¦ç”Ÿã«ã©ã®ã‚ˆã†ãªç›®æ¨™è¨­å®šã‚’ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ"
    )
    
    # æ¤œç´¢å®Ÿè¡Œ
    col1, col2 = st.columns([1, 5])
    with col1:
        search_button = st.button("ğŸ” æ¤œç´¢", type="primary")
    with col2:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢"):
            if 'query' in st.session_state:
                del st.session_state.query
            st.rerun()
    
    if search_button and query:
        with st.spinner("ğŸ¤– AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            answer, search_results = assistant.get_answer(query, model=model_name)
        
        # å›ç­”è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ’¬ AI ã®å›ç­”")
        st.markdown(answer)
        
        # å‚è€ƒãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“š å‚è€ƒã«ã—ãŸéå»ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½10ä»¶ï¼‰")
        
        for i, result in enumerate(search_results[:10], 1):
            student_name = result['metadata'].get('student_name', 'ä¸æ˜')
            data_type = result['metadata'].get('type', 'unknown')
            subtype = result['metadata'].get('subtype', '')
            similarity = result['similarity']
            
            with st.expander(
                f"{i}. {student_name} - {data_type}: {subtype} (é–¢é€£åº¦: {similarity:.2%})"
            ):
                st.text(result['chunk'])
                st.caption(f"é–¢é€£åº¦ã‚¹ã‚³ã‚¢: {result['distance']:.4f}")
    
    # ä»˜å¸¯æƒ…å ±
    st.markdown("---")
    st.info(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {DATA_FILE}")

if __name__ == "__main__":
    main()
